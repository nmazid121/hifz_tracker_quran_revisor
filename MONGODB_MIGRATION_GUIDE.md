# MongoDB Atlas Migration Guide

## ğŸ¯ **Overview**
This guide walks you through migrating your Quran Hifz Tracker application from local SQLite databases to MongoDB Atlas cloud database for production deployment.

## ğŸ“‹ **Prerequisites**
- QUL implementation completed (local SQLite working)
- Backend Flask server running locally
- Access to create MongoDB Atlas account

## ğŸš€ **Phase 1: MongoDB Atlas Setup**

### Step 1: Create MongoDB Atlas Account
1. Go to [mongodb.com/atlas](https://www.mongodb.com/atlas)
2. Click "Start Free" and create account
3. Choose "Build a cluster" â†’ "Shared Clusters" (Free Tier)
4. Select:
   - **Cloud Provider**: AWS (recommended)
   - **Region**: Choose closest to your users
   - **Cluster Name**: `quran-hifz-cluster`
5. Click "Create Cluster" (takes 1-3 minutes)

### Step 2: Configure Database Access
1. **Create Database User**:
   - Go to "Database Access" in left sidebar
   - Click "Add New Database User"
   - Choose "Password" authentication
   - Username: `quran_app_user`
   - Password: Generate strong password and save it
   - Database User Privileges: "Read and write to any database"
   - Click "Add User"

2. **Configure Network Access**:
   - Go to "Network Access" in left sidebar
   - Click "Add IP Address"
   - Choose "Allow Access from Anywhere" (0.0.0.0/0)
   - Click "Confirm"
   - âš ï¸ **Note**: For production, restrict to specific IPs

### Step 3: Get Connection String
1. Go to "Clusters" and click "Connect"
2. Choose "Connect your application"
3. Select "Python" and version "3.6 or later"
4. Copy the connection string:
   ```
   mongodb+srv://quran_app_user:<password>@quran-hifz-cluster.xxxxx.mongodb.net/<dbname>?retryWrites=true&w=majority
   ```
5. Replace `<password>` with actual password
6. Replace `<dbname>` with `quran_hifz_tracker`

## ğŸ”§ **Phase 2: Backend Preparation**

### Step 1: Install Dependencies
```bash
cd backend
pip install pymongo python-dotenv
pip freeze > requirements.txt
```

### Step 2: Create Environment File
Create `backend/.env`:
```env
# MongoDB Configuration
MONGODB_URI=mongodb+srv://quran_app_user:YOUR_PASSWORD@quran-hifz-cluster.xxxxx.mongodb.net/quran_hifz_tracker?retryWrites=true&w=majority

# Optional: Local SQLite paths (for migration)
QUL_LAYOUT_DB=../qul_downloads/qudratullah-indopak-15-lines.db
QUL_SCRIPT_DB=../qul_downloads/indopak.db
```

### Step 3: Create Database Connection Module
Create `backend/mongodb_connection.py`:
```python
from pymongo import MongoClient
import os
from dotenv import load_dotenv

load_dotenv()

def get_mongodb_client():
    """Get MongoDB client connection"""
    try:
        client = MongoClient(os.getenv('MONGODB_URI'))
        # Test connection
        client.admin.command('ping')
        print("âœ… MongoDB connection successful")
        return client
    except Exception as e:
        print(f"âŒ MongoDB connection failed: {e}")
        return None

def get_database():
    """Get the main database"""
    client = get_mongodb_client()
    if client:
        return client['quran_hifz_tracker']
    return None

# Collections
def get_collections():
    """Get all collections"""
    db = get_database()
    if db:
        return {
            'pages': db.pages,
            'words': db.words,
            'surahs': db.surahs,
            'recitations': db.recitations
        }
    return None
```

## ğŸ”„ **Phase 3: Data Migration Script**

Create `backend/migrate_to_mongodb.py`:
```python
#!/usr/bin/env python3
"""
One-time migration script to move QUL data from SQLite to MongoDB Atlas
"""

import sqlite3
import json
from datetime import datetime
from mongodb_connection import get_collections
from database import init_database, get_all_recitations

def migrate_qul_layout_data():
    """Migrate page layout data from QUL SQLite to MongoDB"""
    print("ğŸ“„ Migrating page layout data...")
    
    collections = get_collections()
    if not collections:
        return False
    
    # Connect to SQLite
    conn = sqlite3.connect('../qul_downloads/qudratullah-indopak-15-lines.db')
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # Get all pages data
    cursor.execute('SELECT * FROM pages ORDER BY page_number, line_number')
    pages_data = []
    
    for row in cursor.fetchall():
        page_doc = {
            'page_number': row['page_number'],
            'line_number': row['line_number'],
            'line_type': row['line_type'],
            'is_centered': bool(row['is_centered']),
            'first_word_id': row['first_word_id'] if row['first_word_id'] else None,
            'last_word_id': row['last_word_id'] if row['last_word_id'] else None,
            'surah_number': row['surah_number'],
            'created_at': datetime.utcnow()
        }
        pages_data.append(page_doc)
    
    conn.close()
    
    # Insert into MongoDB
    if pages_data:
        collections['pages'].delete_many({})  # Clear existing
        result = collections['pages'].insert_many(pages_data)
        print(f"âœ… Migrated {len(result.inserted_ids)} page layout records")
        return True
    
    return False

def migrate_qul_words_data():
    """Migrate words data from QUL SQLite to MongoDB"""
    print("ğŸ“ Migrating words data...")
    
    collections = get_collections()
    if not collections:
        return False
    
    # Connect to SQLite
    conn = sqlite3.connect('../qul_downloads/indopak.db')
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    # Get all words data
    cursor.execute('SELECT * FROM words ORDER BY id')
    words_data = []
    
    for row in cursor.fetchall():
        word_doc = {
            'id': row['id'],
            'text': row['text'],
            'created_at': datetime.utcnow()
        }
        words_data.append(word_doc)
    
    conn.close()
    
    # Insert into MongoDB in batches (words table is large)
    if words_data:
        collections['words'].delete_many({})  # Clear existing
        
        batch_size = 1000
        total_inserted = 0
        
        for i in range(0, len(words_data), batch_size):
            batch = words_data[i:i + batch_size]
            result = collections['words'].insert_many(batch)
            total_inserted += len(result.inserted_ids)
            print(f"  Inserted batch {i//batch_size + 1}: {len(result.inserted_ids)} words")
        
        print(f"âœ… Migrated {total_inserted} word records")
        return True
    
    return False

def migrate_surah_names():
    """Migrate surah names to MongoDB"""
    print("ğŸ“š Creating surah names collection...")
    
    collections = get_collections()
    if not collections:
        return False
    
    surah_names = {
        1: "Ø§Ù„ÙØ§ØªØ­Ø©", 2: "Ø§Ù„Ø¨Ù‚Ø±Ø©", 3: "Ø¢Ù„ Ø¹Ù…Ø±Ø§Ù†", 4: "Ø§Ù„Ù†Ø³Ø§Ø¡", 5: "Ø§Ù„Ù…Ø§Ø¦Ø¯Ø©",
        6: "Ø§Ù„Ø£Ù†Ø¹Ø§Ù…", 7: "Ø§Ù„Ø£Ø¹Ø±Ø§Ù", 8: "Ø§Ù„Ø£Ù†ÙØ§Ù„", 9: "Ø§Ù„ØªÙˆØ¨Ø©", 10: "ÙŠÙˆÙ†Ø³",
        11: "Ù‡ÙˆØ¯", 12: "ÙŠÙˆØ³Ù", 13: "Ø§Ù„Ø±Ø¹Ø¯", 14: "Ø¥Ø¨Ø±Ø§Ù‡ÙŠÙ…", 15: "Ø§Ù„Ø­Ø¬Ø±",
        16: "Ø§Ù„Ù†Ø­Ù„", 17: "Ø§Ù„Ø¥Ø³Ø±Ø§Ø¡", 18: "Ø§Ù„ÙƒÙ‡Ù", 19: "Ù…Ø±ÙŠÙ…", 20: "Ø·Ù‡",
        21: "Ø§Ù„Ø£Ù†Ø¨ÙŠØ§Ø¡", 22: "Ø§Ù„Ø­Ø¬", 23: "Ø§Ù„Ù…Ø¤Ù…Ù†ÙˆÙ†", 24: "Ø§Ù„Ù†ÙˆØ±", 25: "Ø§Ù„ÙØ±Ù‚Ø§Ù†",
        26: "Ø§Ù„Ø´Ø¹Ø±Ø§Ø¡", 27: "Ø§Ù„Ù†Ù…Ù„", 28: "Ø§Ù„Ù‚ØµØµ", 29: "Ø§Ù„Ø¹Ù†ÙƒØ¨ÙˆØª", 30: "Ø§Ù„Ø±ÙˆÙ…",
        31: "Ù„Ù‚Ù…Ø§Ù†", 32: "Ø§Ù„Ø³Ø¬Ø¯Ø©", 33: "Ø§Ù„Ø£Ø­Ø²Ø§Ø¨", 34: "Ø³Ø¨Ø£", 35: "ÙØ§Ø·Ø±",
        36: "ÙŠØ³", 37: "Ø§Ù„ØµØ§ÙØ§Øª", 38: "Øµ", 39: "Ø§Ù„Ø²Ù…Ø±", 40: "ØºØ§ÙØ±",
        41: "ÙØµÙ„Øª", 42: "Ø§Ù„Ø´ÙˆØ±Ù‰", 43: "Ø§Ù„Ø²Ø®Ø±Ù", 44: "Ø§Ù„Ø¯Ø®Ø§Ù†", 45: "Ø§Ù„Ø¬Ø§Ø«ÙŠØ©",
        46: "Ø§Ù„Ø£Ø­Ù‚Ø§Ù", 47: "Ù…Ø­Ù…Ø¯", 48: "Ø§Ù„ÙØªØ­", 49: "Ø§Ù„Ø­Ø¬Ø±Ø§Øª", 50: "Ù‚",
        51: "Ø§Ù„Ø°Ø§Ø±ÙŠØ§Øª", 52: "Ø§Ù„Ø·ÙˆØ±", 53: "Ø§Ù„Ù†Ø¬Ù…", 54: "Ø§Ù„Ù‚Ù…Ø±", 55: "Ø§Ù„Ø±Ø­Ù…Ù†",
        56: "Ø§Ù„ÙˆØ§Ù‚Ø¹Ø©", 57: "Ø§Ù„Ø­Ø¯ÙŠØ¯", 58: "Ø§Ù„Ù…Ø¬Ø§Ø¯Ù„Ø©", 59: "Ø§Ù„Ø­Ø´Ø±", 60: "Ø§Ù„Ù…Ù…ØªØ­Ù†Ø©",
        61: "Ø§Ù„ØµÙ", 62: "Ø§Ù„Ø¬Ù…Ø¹Ø©", 63: "Ø§Ù„Ù…Ù†Ø§ÙÙ‚ÙˆÙ†", 64: "Ø§Ù„ØªØ­Ø±ÙŠÙ…", 65: "Ø§Ù„Ù…Ù„Ùƒ",
        66: "Ø§Ù„Ù‚Ù„Ù…", 67: "Ø§Ù„Ø­Ø§Ù‚Ø©", 68: "Ø§Ù„Ù…Ø¹Ø§Ø±Ø¬", 69: "Ù†ÙˆØ­", 70: "Ø§Ù„Ø¬Ù†",
        71: "Ø§Ù„Ù…Ø²Ù…Ù„", 72: "Ø§Ù„Ù…Ø¯Ø«Ø±", 73: "Ø§Ù„Ù‚ÙŠØ§Ù…Ø©", 74: "Ø§Ù„Ø¥Ù†Ø³Ø§Ù†", 75: "Ø§Ù„Ù…Ø±Ø³Ù„Ø§Øª",
        76: "Ø§Ù„Ù†Ø¨Ø£", 77: "Ø§Ù„Ù†Ø§Ø²Ø¹Ø§Øª", 78: "Ø¹Ø¨Ø³", 79: "Ø§Ù„ØªÙƒÙˆÙŠØ±", 80: "Ø§Ù„Ø§Ù†ÙØ·Ø§Ø±",
        81: "Ø§Ù„Ù…Ø·ÙÙÙŠÙ†", 82: "Ø§Ù„Ø§Ù†Ø´Ù‚Ø§Ù‚", 83: "Ø§Ù„Ø¨Ø±ÙˆØ¬", 84: "Ø§Ù„Ø·Ø§Ø±Ù‚", 85: "Ø§Ù„Ø£Ø¹Ù„Ù‰",
        86: "Ø§Ù„ØºØ§Ø´ÙŠØ©", 87: "Ø§Ù„ÙØ¬Ø±", 88: "Ø§Ù„Ø¨Ù„Ø¯", 89: "Ø§Ù„Ø´Ù…Ø³", 90: "Ø§Ù„Ù„ÙŠÙ„",
        91: "Ø§Ù„Ø¶Ø­Ù‰", 92: "Ø§Ù„Ø´Ø±Ø­", 93: "Ø§Ù„ØªÙŠÙ†", 94: "Ø§Ù„Ø¹Ù„Ù‚", 95: "Ø§Ù„Ø¨ÙŠÙ†Ø©",
        96: "Ø§Ù„Ø²Ù„Ø²Ù„Ø©", 97: "Ø§Ù„Ø¹Ø§Ø¯ÙŠØ§Øª", 98: "Ø§Ù„Ù‚Ø§Ø±Ø¹Ø©", 99: "Ø§Ù„ØªÙƒØ§Ø«Ø±", 100: "Ø§Ù„Ø¹ØµØ±",
        101: "Ø§Ù„Ù‡Ù…Ø²Ø©", 102: "Ø§Ù„ÙÙŠÙ„", 103: "Ù‚Ø±ÙŠØ´", 104: "Ø§Ù„Ù…Ø§Ø¹ÙˆÙ†", 105: "Ø§Ù„ÙƒÙˆØ«Ø±",
        106: "Ø§Ù„ÙƒØ§ÙØ±ÙˆÙ†", 107: "Ø§Ù„Ù†ØµØ±", 108: "Ø§Ù„Ù…Ø³Ø¯", 109: "Ø§Ù„Ø¥Ø®Ù„Ø§Øµ", 110: "Ø§Ù„ÙÙ„Ù‚",
        111: "Ø§Ù„Ù†Ø§Ø³"
    }
    
    surah_docs = []
    for number, name in surah_names.items():
        surah_doc = {
            'number': number,
            'arabic_name': name,
            'created_at': datetime.utcnow()
        }
        surah_docs.append(surah_doc)
    
    collections['surahs'].delete_many({})  # Clear existing
    result = collections['surahs'].insert_many(surah_docs)
    print(f"âœ… Created {len(result.inserted_ids)} surah records")
    return True

def migrate_existing_recitations():
    """Migrate existing recitation data"""
    print("ğŸ¤ Migrating existing recitations...")
    
    collections = get_collections()
    if not collections:
        return False
    
    # Get existing recitations from SQLite
    init_database()  # Initialize local database
    recitations = get_all_recitations()
    
    if not recitations:
        print("â„¹ï¸ No existing recitations to migrate")
        return True
    
    # Convert to MongoDB documents
    recitation_docs = []
    for rec in recitations:
        # Convert SQLite record to MongoDB document
        doc = dict(rec)
        doc['created_at'] = datetime.utcnow()
        recitation_docs.append(doc)
    
    collections['recitations'].delete_many({})  # Clear existing
    result = collections['recitations'].insert_many(recitation_docs)
    print(f"âœ… Migrated {len(result.inserted_ids)} recitation records")
    return True

def create_indexes():
    """Create database indexes for performance"""
    print("ğŸ“Š Creating database indexes...")
    
    collections = get_collections()
    if not collections:
        return False
    
    # Pages collection indexes
    collections['pages'].create_index('page_number')
    collections['pages'].create_index([('page_number', 1), ('line_number', 1)])
    collections['pages'].create_index('surah_number')
    
    # Words collection indexes
    collections['words'].create_index('id', unique=True)
    
    # Surahs collection indexes
    collections['surahs'].create_index('number', unique=True)
    
    # Recitations collection indexes
    collections['recitations'].create_index('page_number')
    collections['recitations'].create_index('surah_name')
    collections['recitations'].create_index('recitation_date')
    
    print("âœ… Database indexes created")
    return True

def verify_migration():
    """Verify that migration was successful"""
    print("ğŸ” Verifying migration...")
    
    collections = get_collections()
    if not collections:
        return False
    
    # Count records
    pages_count = collections['pages'].count_documents({})
    words_count = collections['words'].count_documents({})
    surahs_count = collections['surahs'].count_documents({})
    recitations_count = collections['recitations'].count_documents({})
    
    print(f"ğŸ“Š Migration Summary:")
    print(f"   - Pages: {pages_count:,} records")
    print(f"   - Words: {words_count:,} records")
    print(f"   - Surahs: {surahs_count} records")
    print(f"   - Recitations: {recitations_count} records")
    
    # Test a sample query
    try:
        sample_page = collections['pages'].find_one({'page_number': 1})
        sample_word = collections['words'].find_one({'id': 1})
        
        if sample_page and sample_word:
            print("âœ… Sample queries successful - migration verified!")
            return True
        else:
            print("âŒ Sample queries failed - migration may be incomplete")
            return False
    except Exception as e:
        print(f"âŒ Verification failed: {e}")
        return False

def main():
    """Run the complete migration"""
    print("ğŸš€ Starting MongoDB Atlas Migration")
    print("=" * 50)
    
    steps = [
        ("QUL Page Layout Data", migrate_qul_layout_data),
        ("QUL Words Data", migrate_qul_words_data),
        ("Surah Names", migrate_surah_names),
        ("Existing Recitations", migrate_existing_recitations),
        ("Database Indexes", create_indexes),
        ("Migration Verification", verify_migration)
    ]
    
    for step_name, step_func in steps:
        print(f"\nğŸ“‹ {step_name}")
        success = step_func()
        if not success:
            print(f"âŒ Migration failed at: {step_name}")
            return False
    
    print("\n" + "=" * 50)
    print("ğŸ‰ Migration completed successfully!")
    print("ğŸ”„ Next step: Update app.py to use MongoDB")
    return True

if __name__ == "__main__":
    main()
```

## ğŸ”§ **Phase 4: Update Backend Code**

### Step 1: Modify app.py
Update the database functions in `app.py` to use MongoDB:

```python
# Add at the top of app.py
from mongodb_connection import get_collections

# Replace the existing get_pages function
def get_pages(page_number=None):
    collections = get_collections()
    if not collections:
        return []
    
    if page_number is not None:
        cursor = collections['pages'].find({'page_number': page_number}).sort('line_number', 1)
    else:
        cursor = collections['pages'].find({}).sort([('page_number', 1), ('line_number', 1)])
    
    return list(cursor)

# Replace the existing get_words function
def get_words(word_ids=None):
    collections = get_collections()
    if not collections:
        return []
    
    if word_ids:
        cursor = collections['words'].find({'id': {'$in': word_ids}})
    else:
        cursor = collections['words'].find({}).sort('id', 1)
    
    return list(cursor)

# Update surah names endpoint
@app.route('/api/quran/surah-names')
def get_surah_names():
    collections = get_collections()
    if not collections:
        return jsonify({'error': 'Database connection failed'}), 500
    
    surahs = collections['surahs'].find({}).sort('number', 1)
    surah_names = {str(surah['number']): surah['arabic_name'] for surah in surahs}
    return jsonify(surah_names)
```

## ğŸ§ª **Phase 5: Testing**

### Step 1: Test Migration
```bash
cd backend
python3 migrate_to_mongodb.py
```

### Step 2: Test Application
```bash
# Start backend with MongoDB
python3 app.py

# In another terminal, test endpoints
python3 ../test_qul_endpoints.py
```

### Step 3: Test Frontend
```bash
cd frontend
npm start
```

## ğŸš¨ **Troubleshooting**

### Common Issues:
1. **Connection Timeout**: Check network access whitelist in Atlas
2. **Authentication Failed**: Verify username/password in connection string
3. **Database Not Found**: Ensure database name matches in connection string
4. **Slow Queries**: Check if indexes were created properly

### Recovery Plan:
- Keep local SQLite files as backup
- Can revert to SQLite if MongoDB migration fails
- Test thoroughly in development before production

## ğŸ¯ **Next Steps After Migration**
1. Update deployment scripts for production
2. Set up MongoDB monitoring and alerts
3. Implement data backup procedures
4. Optimize queries based on usage patterns
5. Plan for scaling as user base grows

---

**ğŸ‰ Once completed, your application will be ready for production deployment with MongoDB Atlas!**